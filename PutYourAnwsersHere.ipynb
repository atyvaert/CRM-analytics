{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import access\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas.core.reshape.concat import concat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping EmployeeData (HVC_AM0)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Reading the file and storing each line in the list text\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_AM0.csv\", \"r\") as f:\n",
    "    textEmployees = f.readlines()\n",
    "textEmployees.pop(0)\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "CompanyEmployeesDict = {}\n",
    "\n",
    "for e in textEmployees:\n",
    "    Employee_ID, EmployeeNumber, Name, Postcode, Location, Language = e.replace(\"\\n\",\"\").split(\";\")\n",
    "    Employee_ID=int(Employee_ID)\n",
    "    Postcode=int(Postcode)\n",
    "    CompanyEmployeesDict[Employee_ID]= {\"EmployeeNumber\":EmployeeNumber,\"Name\": Name, \"Postcode\": Postcode, \"Location\": Location,\"Language\": Language }\n",
    "\n",
    "\n",
    "#Some Employees do not have a EmployeeNumber: We set the EmployeeNumber of these employees to 0\n",
    "#In this way we can convert all to a float\n",
    "for e in CompanyEmployeesDict:\n",
    "    E_ID = CompanyEmployeesDict[e][\"EmployeeNumber\"]\n",
    "    if(E_ID == \"\"):\n",
    "        CompanyEmployeesDict[e][\"EmployeeNumber\"]=\"0\"\n",
    "    CompanyEmployeesDict[e][\"EmployeeNumber\"] = int(float(CompanyEmployeesDict[e][\"EmployeeNumber\"]))   \n",
    "\n",
    "df_CompanyEmployees = pd.DataFrame.from_dict(CompanyEmployeesDict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping ProductData (HVC_AR0)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_AR0.csv\", \"r\") as f:\n",
    "    textProducts = f.readlines()\n",
    "textProducts.pop(0)\n",
    "\n",
    "CompanyProductsDict = {}\n",
    "for e in textProducts:\n",
    "    ProductID, Description, Category, Family, Price = e.replace(\"\\n\",\"\").split(\";\")\n",
    "    ProductID = int(ProductID)\n",
    "    CompanyProductsDict[ProductID]= {\"Description\":Description,\"Category\": Category, \"Family\": Family, \"Price\": Price}\n",
    "   \n",
    "#Some prices are missing   \n",
    "for e in CompanyProductsDict:\n",
    "  PriceCheck = CompanyProductsDict[e][\"Price\"]\n",
    "  if(PriceCheck==\"\"):\n",
    "        CompanyProductsDict[e][\"Price\"]=\"0.0\"\n",
    "  CompanyProductsDict[e][\"Price\"]=float(CompanyProductsDict[e][\"Price\"])  \n",
    "\n",
    "#Whenever they are Coupons they are not assigned a family\n",
    "#We assign Coupon to its Family for clearity\n",
    "for e in CompanyProductsDict:\n",
    "  PriceCheck = CompanyProductsDict[e][\"Family\"]\n",
    "  if(PriceCheck==\"\"):\n",
    "        CompanyProductsDict[e][\"Family\"]=\"Coupon\"\n",
    "\n",
    "df_Products = pd.DataFrame.from_dict(CompanyProductsDict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping Reviews Data (HVC_CUSTOMER_REVIEWS)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------   \n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_CUSTOMER_REVIEWS.csv\", \"r\") as f:\n",
    "    textCustReviews = f.readlines()\n",
    "textCustReviews.pop(0)\n",
    "\n",
    "CompanyReviewsDict = {}\n",
    "for e in textCustReviews:\n",
    "    CustomerID, Review  = e.replace(\"\\n\",\"\").split(\";\")\n",
    "    CustomerID = int(CustomerID)\n",
    "    CompanyReviewsDict[CustomerID]= {\"Review\": Review}\n",
    "\n",
    "df_Reviews = pd.DataFrame.from_dict(CompanyReviewsDict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping Depot data (HVC_DEPOT)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Reading the file and storing each line in the list text\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_DEPOT.csv\", \"r\") as f:\n",
    "    text_Depot = f.readlines()\n",
    "text_Depot.pop(0)\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "Depot_Dict = {}\n",
    "\n",
    "for dep in text_Depot:\n",
    "    Depot_Id, Depot_Location, Depot_Route = dep.replace(\"\\n\",\"\").split(\";\")\n",
    "    Depot_Id = int(Depot_Id)\n",
    "    Depot_Route = int(Depot_Route)\n",
    "    Depot_Dict[Depot_Id] = {\"DEPOT\":Depot_Location, \"HVROUTETEMPLATE_NRID\":Depot_Route}\n",
    "\n",
    "#The Depot_Id and HVROUTETEMPLATE_NRID are both integers, Depot_Location\n",
    "#The names of the keys are based on the table descriptions for easy looking up in case of further calculations\n",
    "#There are no missing values in our dictionnary so further preprocessing is not necessary.\n",
    "\n",
    "df_Depot = pd.DataFrame.from_dict(Depot_Dict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping DaysOfWeek (HVC_HVDAYOFWEEK)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_HVDAYOFWEEK.csv\", \"r\") as f:\n",
    "    text_DayOfWeek = f.readlines()\n",
    "text_DayOfWeek.pop(0)\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "DayOfWeek_Dict = {}\n",
    "\n",
    "for day in text_DayOfWeek:\n",
    "    HVDAYOFWEEK_NRID, DAY = day.replace(\"\\n\",\"\").split(\";\")\n",
    "    HVDAYOFWEEK_NRID = int(float(HVDAYOFWEEK_NRID))\n",
    "    DayOfWeek_Dict[int(HVDAYOFWEEK_NRID)] = DAY\n",
    "\n",
    "\n",
    "#The HVDAYOFWEEK_NRID is an integer, DAY is a string. \n",
    "#!! important notice for further caclulations, the first day (day with id = 1) is a sunday! Not a monday!\n",
    "df_DaysOfWeek = pd.DataFrame.from_dict(DayOfWeek_Dict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping Position data (HVC_HVPOSITION)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_HVPOSITION.csv\", \"r\") as f:\n",
    "    text_Position = f.readlines()\n",
    "text_Position.pop(0)\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "Position_Dict = {}\n",
    "\n",
    "for loc in text_Position:\n",
    "    SO0_NRID, LONG, LAT = loc.replace(\"\\n\",\"\").split(\";\")\n",
    "    SO0_NRID = int(float(SO0_NRID))\n",
    "    LONG = float(LONG)\n",
    "    LAT = float(LAT)\n",
    "    Position_Dict[SO0_NRID] = {\"LONG\":LONG, \"LAT\":LAT}\n",
    "\n",
    "#SO0_NRID is int, LONG and LAT are both float values.\n",
    "\n",
    "df_Position = pd.DataFrame.from_dict(Position_Dict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping Route Template data (HVC_HVROUTETEMPLATE)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_HVROUTETEMPLATE.csv\", \"r\") as f:\n",
    "    textRouteTemplate = f.readlines()\n",
    "    textRouteTemplate.pop(0)\n",
    "    \n",
    "RouteTemplate_Dict = {}\n",
    "\n",
    "for route in textRouteTemplate:\n",
    "    HVROUTETEMPLATE_NRID, REGION, WEEKORDER, HVDAYOFWEEK_NRID = route.replace(\"\\n\",\"\").split(\";\")\n",
    "    HVROUTETEMPLATE_NRID=int(float(HVROUTETEMPLATE_NRID))\n",
    "    RouteTemplate_Dict[HVROUTETEMPLATE_NRID] = {\"REGION\": REGION, \"WEEKORDER\": WEEKORDER, \"DAYOFWEEK_NRID\": HVDAYOFWEEK_NRID}        \n",
    "\n",
    "df_RouteTemplate = pd.DataFrame.from_dict(RouteTemplate_Dict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping Visit Outcome data (HVC_HVVISITOUTCOME)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_HVVISITOUTCOME.csv\", \"r\") as f:\n",
    "    textVisitOutcome = list()\n",
    "    for line in f:\n",
    "        line = line.replace(\"\\n\",\"\")\n",
    "        obs = line.split(\";\")\n",
    "        textVisitOutcome.append(obs)\n",
    "\n",
    "column_names = textVisitOutcome[0]\n",
    "textVisitOutcome.pop(0)\n",
    "VisitOucome_Dict = {}\n",
    "\n",
    "for visit in textVisitOutcome:\n",
    "    VisitOucome_Dict[visit[1]] = visit[0]\n",
    "\n",
    "\n",
    "df_VisitOutcome = pd.DataFrame.from_dict(VisitOucome_Dict, orient = 'index')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping TransactionData (HVC_HVVISITRESULT)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Reading the file and storing each line in the list text\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_HVVISITRESULT.csv\", \"r\") as f:\n",
    "    textVisit = f.readlines()\n",
    "textVisit.pop(0)\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "CompanyVisitDict = {}\n",
    "\n",
    "for e in textVisit:\n",
    "    Visit_ID, Customer_ID, Employee_ID, VisitOutcome_ID, Time, Date, Amount, paymentMethod = e.replace(\"\\n\",\"\").split(\";\")\n",
    "    Visit_ID= int(Visit_ID)\n",
    "\n",
    "    yYear, mMonth, dDay = Date.split(\"-\")\n",
    "    yYear = int(yYear)\n",
    "    mMonth = int(mMonth)\n",
    "    dDay = int(dDay)\n",
    "    Date=datetime.date(yYear,mMonth,dDay)\n",
    "\n",
    "    Customer_ID= int(Customer_ID)\n",
    "    Employee_ID= int(Employee_ID)\n",
    "    VisitOutcome_ID= int(VisitOutcome_ID)\n",
    "    Amount= float(Amount)\n",
    "    CompanyVisitDict[Visit_ID]= {\"Customer_ID\":Customer_ID,\"Employee_ID\": Employee_ID, \"VisitOutcome_ID\": VisitOutcome_ID, \"Time\": Time,\"Date\": Date, \"Amount\": Amount, \"paymentMethod\": paymentMethod }\n",
    "\n",
    "#Some visits do not have a payment method recorded: We set the paymentMethod of these cases to the None variable\n",
    "#Maybe these missing values will have value later on\n",
    "for e in CompanyVisitDict:\n",
    "    P_method = CompanyVisitDict[e][\"paymentMethod\"]\n",
    "    if(P_method == \"\"):\n",
    "        CompanyVisitDict[e][\"paymentMethod\"]= None\n",
    "\n",
    "df_CompanyVisit = pd.DataFrame.from_dict(CompanyVisitDict, orient = 'index')\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping EmployeeData (HVC_SO0)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#Reading the file and storing each line in the list text\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_SO0.csv\", \"r\") as f:\n",
    "    textCustomerType = f.readlines()\n",
    "textCustomerType.pop(0)\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "CustomerTypeDict = {}\n",
    "\n",
    "for e in textCustomerType:\n",
    "    Customer_ID, RouteTemplate_ID, CustomerType, Postcode, Language, Season = e.replace(\"\\n\",\"\").split(\";\")\n",
    "    Customer_ID=int(float(Customer_ID))\n",
    "    RouteTemplate_ID=int(float(RouteTemplate_ID))\n",
    "    Postcode = int(float(Postcode))\n",
    "    CustomerTypeDict[Customer_ID]= {\"RouteTemplate_ID\":RouteTemplate_ID,\"CustomerType\": CustomerType, \"Postcode\": Postcode, \"Language\": Language,\"Season\": Season}\n",
    "\n",
    "\n",
    "df_CustomerType = pd.DataFrame.from_dict(CustomerTypeDict, orient = 'index')\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "#Prepping ProductData (HVC_VISITRESULTDETAILS)\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "with open (\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/HVC_VISITRESULTDETAILS.csv\", \"r\") as f:\n",
    "    textVisitDetails = f.readlines()\n",
    "textVisitDetails.pop(0)\n",
    "\n",
    "\n",
    "#We make a dictionnary based on the data\n",
    "VisitDetailsDict = {}\n",
    "\n",
    "\n",
    "for e in textVisitDetails:\n",
    "    VisitDetails_ID, Product_ID, Quantity, Visit_ID = e.replace(\"\\n\",\"\").split(\";\")\n",
    "    VisitDetails_ID=int(VisitDetails_ID)\n",
    "    Product_ID=int(Product_ID)\n",
    "    Quantity=int(float(Quantity))\n",
    "    Visit_ID=int(float(Visit_ID))\n",
    "    VisitDetailsDict[VisitDetails_ID]= {\"Product_ID\":Product_ID,\"Quantity\": Quantity, \"Visit_ID\": Visit_ID}\n",
    "\n",
    "df_VisitDetails = pd.DataFrame.from_dict(VisitDetailsDict, orient = 'index')\n",
    "\n",
    "#We add a a selfmade database of average and median household income per postal code, the document is called Income_per_postcode2.csv\n",
    "df_Income_per_postcode = pd.read_csv(\"C:/Users/HP/Desktop/Dev.Maarten/Python/Project/Data/Income_per_postcode2.csv\")\n",
    "#This dataframe may be important for several regressions questions \n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#This gives us the following 11 dataframes to work with:\n",
    "# 1  df_CompanyEmployees (HVC_AM0)\n",
    "# 2  df_Products (HVC_AR0)\n",
    "# 3  df_Reviews  (HVC_CUSTOMER_REVIEWS)\n",
    "# 4  df_Depot  (HVC_DEPOT)\n",
    "# 5  df_DaysOfWeek (HVC_HVDAYOFWEEK)\n",
    "# 6  df_Position (HVC_HVPOSiTION)\n",
    "# 7  df_RouteTemplate (HVC_HVROUTETEMPLATE)\n",
    "# 8  df_VisitOutcome (HVC_HVVISITOUTCOME)\n",
    "# 9  df_CompanyVisit (HVC_VISITRESULT)\n",
    "# 10 df_CustomerType (HVC_SO0)\n",
    "# 11 df_VisitDetails (HVC_VISITRESULTDETAILS)\n",
    "# 12 df_Income_per_postcode (Income_per_postcode2, data source link: https://statbel.fgov.be/nl/themas/huishoudens/fiscale-inkomens#panel-13 )\",\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "#Q1: What are the Products?\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.1 What are the most frequently bought products?\n",
    "Aureum = df_VisitDetails.groupby(\"Product_ID\")[\"Quantity\"].sum()\n",
    "newAU = pd.merge(Aureum, df_Products, how=\"left\", on=Aureum.keys())\n",
    "Revenue = newAU[\"Price\"]*newAU[\"Quantity\"]\n",
    "newAU[\"RevenueProduct\"] = Revenue\n",
    "\n",
    "\n",
    "#Most products sold in ammount\n",
    "BestAmountSoldProducts = newAU.sort_values(by=\"Quantity\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.2 Which products render the most revenue?\n",
    "BestRevProducts = newAU.sort_values(by=\"RevenueProduct\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.3 Which products are bought the most in the region of Brussels, Antwerp, â€¦?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.4 Are product purchases correlated? Are some products often purchased together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.5 What are the total sales generated for each product family?\n",
    "#Based on Family\n",
    "#Generated Revenue\n",
    "BestRevFamily=BestRevProducts.groupby(\"Family\")[\"RevenueProduct\"].sum().sort_values(ascending=False)\n",
    "#Based on Family\n",
    "#Amount sold\n",
    "BestAmountFamily=BestAmountSoldProducts.groupby(\"Family\")[\"Quantity\"].sum().sort_values(ascending=False)\n",
    "\n",
    "#Based on Catogery\n",
    "#Generated Revenue\n",
    "BestRevCat=BestRevProducts.groupby(\"Category\")[\"RevenueProduct\"].sum().sort_values(ascending=False)\n",
    "\n",
    "#Based on Catogery\n",
    "#Amount sold\n",
    "BestAmountCat=BestRevProducts.groupby(\"Category\")[\"Quantity\"].sum().sort_values(ascending=False)\n",
    "print(BestAmountCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.6 Does the weather / seasonal changes have an effect on the total revenue?\n",
    "#IMPORTANT This question requires the dataFrame newAU from 1.1\n",
    "df_CompanyVisit\n",
    "\n",
    "#This is used to define a function that calculates which season a given date is\n",
    "#This function: get_season returns the season of a date\n",
    "#We add this to a new Column Season\n",
    "Y=2020\n",
    "seasons = [('Winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "           ('Spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "           ('Summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "           ('Autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "           ('Winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "\n",
    "def get_season(now):\n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)\n",
    "\n",
    "df_CompanyVisit[\"Season\"]=df_CompanyVisit[\"Date\"].apply(get_season)\n",
    "df_Seasonality=df_CompanyVisit.groupby(\"Season\")[\"Amount\"].sum()\n",
    "#print(df_Seasonality.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#Q2 Who are the customers?\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.1 What do customers buy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'timedelta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-4acb5583332f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Q2.2 Which customers left the company?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmostRecent\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_CompanyVisit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmostRecentTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmostRecent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m182\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_CompanyVisit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LastVisit\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf_CompanyVisit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0misOk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdateCh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'timedelta'"
     ]
    }
   ],
   "source": [
    "#Q2.2 Which customers left the company?\n",
    "#mostRecent= max(df_CompanyVisit[\"Date\"]) - datetime.timedelta(0)\n",
    "#mostRecentTest = mostRecent - datetime.timedelta(182)\n",
    "#df_CompanyVisit[\"LastVisit\"]= datetime.date.today() - df_CompanyVisit[\"Date\"]\n",
    "#def isOk(dateCh: datetime.date):\n",
    " #   if((mostRecent-dateCh)> (mostRecent-mostRecentTest)):\n",
    "  #      return True\n",
    "   # else:\n",
    "    #    return False\n",
    "#df_CompanyVisit[\"Churn?\"]=df_CompanyVisit[\"Date\"].apply(isOk)        \n",
    "#print(df_CompanyVisit.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.3 Which customers have the highest CLV?\n",
    "df_OnlySuccesFullVisits= df_CompanyVisit[df_CompanyVisit[\"VisitOutcome_ID\"] == 2]\n",
    "df_OnlySuccesFullVisits= df_OnlySuccesFullVisits.sort_values(\"Customer_ID\")\n",
    "#We sum the amounts of money spent per Customer_ID and this gives us after sorting the CLV of all Customers in descending order\n",
    "df_CLV=df_OnlySuccesFullVisits.groupby(\"Customer_ID\")[\"Amount\"].sum().sort_values(ascending=False)\n",
    "#print(df_CLV.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.4 What is the relationship between leaving the company and buying patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.5 Are there clusters of customers? How would you describe these different clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.6 Do customers have different buying patterns during the weekend?\n",
    "\n",
    "#This method uses the weekday function to determine the day of the week starting \n",
    "#At 0 for Monday and ending on 6 for Sunday for a given month and year\n",
    "#In this way if the returned number is larger than 4 (Friday) it is a weekendDay\n",
    "def getWeekIndex(d: datetime.date):\n",
    "    if(d.weekday()>4):\n",
    "        return \"weekend\"\n",
    "    else:\n",
    "        return \"weekday\"\n",
    "\n",
    "#We add a new Column explaining wheter it is a weekday or weekend based on the Date index\n",
    "df_CompanyVisit[\"DateIndex\"] = df_CompanyVisit[\"Date\"].apply(getWeekIndex)\n",
    "df_CompanyVisit[\"Visit_ID\"] = df_CompanyVisit.index\n",
    "\n",
    "CompleteMerge = pd.merge(df_VisitDetails, df_CompanyVisit, on=\"Visit_ID\")\n",
    "\n",
    "\n",
    "df_Products[\"Product_ID\"] = df_Products.index\n",
    "CompleteMergeProd = pd.merge(CompleteMerge,df_Products, on=\"Product_ID\").drop(columns=[\"paymentMethod\", \"Amount\", \"Time\"])\n",
    "CompleteMergeProd[\"Revenue\"]=CompleteMergeProd[\"Quantity\"]*CompleteMergeProd[\"Price\"]\n",
    "\n",
    "OnlyWeekdays= CompleteMergeProd[CompleteMergeProd[\"DateIndex\"] != \"weekend\"]\n",
    "OnlyWeekends= CompleteMergeProd[CompleteMergeProd[\"DateIndex\"] != \"weekday\"]\n",
    "\n",
    "OnlyWeekdaysCus = OnlyWeekdays.groupby([\"Customer_ID\",\"DateIndex\"])[\"Revenue\"].sum()\n",
    "OnlyWeekendsCus = OnlyWeekends.groupby([\"Customer_ID\",\"DateIndex\"])[\"Revenue\"].sum()\n",
    "Comparison = pd.merge(OnlyWeekendsCus,OnlyWeekdaysCus, on=\"Customer_ID\")\n",
    "\n",
    "#X is weekends Y is weekdays\n",
    "#This shows the difference in Revenue expressed in mean and other statistics\n",
    "#Comparing the weekend and \n",
    "#print(Comparison.describe())\n",
    "\n",
    "\n",
    "OnlyWeekdaysPro =  OnlyWeekdays.groupby([\"Product_ID\",\"DateIndex\"])[\"Revenue\"].sum()\n",
    "OnlyWeekendsPro =  OnlyWeekends.groupby([\"Product_ID\",\"DateIndex\"])[\"Revenue\"].sum()\n",
    "OnlyWeekdaysProMerged = pd.merge(OnlyWeekdaysPro,df_Products, on=\"Product_ID\").drop(columns=\"Price\")\n",
    "OnlyWeekendsProMerged =  pd.merge(OnlyWeekendsPro,df_Products, on=\"Product_ID\").drop(columns=\"Price\")\n",
    "\n",
    "OnlyWeekdaysProMergedFam =  pd.merge(OnlyWeekdaysPro,df_Products, how=\"left\",on=\"Product_ID\").drop(columns=\"Price\").groupby(\"Family\")[\"Revenue\"].sum()\n",
    "OnlyWeekendsProMergedFam =  pd.merge(OnlyWeekendsPro,df_Products, how=\"left\",on=\"Product_ID\").drop(columns=\"Price\").groupby(\"Family\")[\"Revenue\"].sum()\n",
    "\n",
    "#X is weekends Y is weekdays\n",
    "#This show what Family sells more during either weekend or weekday\n",
    "WeekendComparedFam = pd.merge(OnlyWeekendsProMergedFam,OnlyWeekdaysProMergedFam, on=\"Family\")\n",
    "#print(WeekendComparedFam)\n",
    "\n",
    "OnlyWeekdaysProMergedDes =  pd.merge(OnlyWeekdaysPro,df_Products, how=\"left\",on=\"Product_ID\").drop(columns=\"Price\").groupby(\"Description\")[\"Revenue\"].sum()\n",
    "OnlyWeekendsProMergedDes =  pd.merge(OnlyWeekendsPro,df_Products, how=\"left\",on=\"Product_ID\").drop(columns=\"Price\").groupby(\"Description\")[\"Revenue\"].sum()\n",
    "\n",
    "#X is weekends Y is weekdays\n",
    "#This show which products sell more during either weekend or weekday\n",
    "WeekendComparedDis= pd.merge(OnlyWeekendsProMergedDes,OnlyWeekdaysProMergedDes, on=\"Description\")\n",
    "#print(WeekendComparedDis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RouteTemplate_ID CustomerType  Postcode  Language    Season    CLV  \\\n",
      "0       289662608.0      Private      3500         1  All time  285.2   \n",
      "1       289662608.0      Private      3500         1  All time  103.2   \n",
      "2       289658600.0      Private      3500         1  All time  117.0   \n",
      "3       289658600.0      Private      3500         1  All time   82.6   \n",
      "4       289658600.0      Private      3500         1  All time  204.3   \n",
      "\n",
      "  City_name  AVERAGE_INCOME  MEDIAN_INCOME  CustomerTypeNum  \n",
      "0   Hasselt         35091.0        26519.0                2  \n",
      "1   Hasselt         35091.0        26519.0                2  \n",
      "2   Hasselt         35091.0        26519.0                2  \n",
      "3   Hasselt         35091.0        26519.0                2  \n",
      "4   Hasselt         35091.0        26519.0                2  \n",
      "RouteTemplate_ID    float64\n",
      "CustomerType         object\n",
      "Postcode              int64\n",
      "Language              int64\n",
      "Season               object\n",
      "CLV                 float64\n",
      "City_name            object\n",
      "AVERAGE_INCOME      float64\n",
      "MEDIAN_INCOME       float64\n",
      "CustomerTypeNum       int32\n",
      "dtype: object\n",
      "[2 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass copy=      RouteTemplate_ID CustomerType  Postcode Language    Season      CLV  \\\n",
      "0          289662608.0      Private      3500    nl-BE  All time   285.20   \n",
      "1          289662608.0      Private      3500    nl-BE  All time   103.20   \n",
      "2          289658600.0      Private      3500    nl-BE  All time   117.00   \n",
      "3          289658600.0      Private      3500    nl-BE  All time    82.60   \n",
      "4          289658600.0      Private      3500    nl-BE  All time   204.30   \n",
      "...                ...          ...       ...      ...       ...      ...   \n",
      "5273       289757472.0      Private      3960    nl-BE  All time   277.50   \n",
      "5274       289757472.0      Private      3960    nl-BE  All time  1017.65   \n",
      "5275       289757472.0      Private      3960    nl-BE  All time     9.00   \n",
      "5276       289757472.0      Private      3960    nl-BE  All time    34.80   \n",
      "5277       289757472.0      Private      3960    nl-BE  All time     7.10   \n",
      "\n",
      "     City_name  AVERAGE_INCOME  MEDIAN_INCOME  \n",
      "0      Hasselt           35091          26519  \n",
      "1      Hasselt           35091          26519  \n",
      "2      Hasselt           35091          26519  \n",
      "3      Hasselt           35091          26519  \n",
      "4      Hasselt           35091          26519  \n",
      "...        ...             ...            ...  \n",
      "5273      Bree           32371          26294  \n",
      "5274      Bree           32371          26294  \n",
      "5275      Bree           32371          26294  \n",
      "5276      Bree           32371          26294  \n",
      "5277      Bree           32371          26294  \n",
      "\n",
      "[5277 rows x 9 columns] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.13136511e-03,  1.25398350e-02, -7.72384949e+02,  0.00000000e+00])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2.7 Do customer sales differ across different cities? Is there a relationship between customer\n",
    "#sales and average income per inhabitant (and other factors)?\n",
    "##Important!!! running this question requires running question 2.3 for the CLV dataframe\n",
    "df_CustomerType[\"CLV\"]=df_CLV\n",
    "df_CustomerType = df_CustomerType.dropna(axis=\"rows\")\n",
    "df_RouteTemplate[\"RouteTemplate_ID\"]=df_RouteTemplate.index\n",
    "\n",
    "\n",
    "#This compares CLV over all regions merging over Routetempate to get CLV linked to The Region\n",
    "df_CLV_Route = pd.merge(df_CustomerType,df_RouteTemplate, on=\"RouteTemplate_ID\")\n",
    "df_CLV_Route_Region = df_CLV_Route.groupby(\"REGION\")[\"CLV\"].sum()\n",
    "#print(df_CLV_Route_Region)\n",
    "\n",
    "#Compares CLV over all Cities\n",
    "df_Depot=df_Depot.rename(columns={\"HVROUTETEMPLATE_NRID\": \"RouteTemplate_ID\"})\n",
    "df_CLV_Cities= pd.merge(df_CLV_Route,df_Depot,on=\"RouteTemplate_ID\").groupby(\"DEPOT\")[\"CLV\"].sum()\n",
    "#df_CLV_Cities.head(5)\n",
    "\n",
    "#df_Income_per_postcode\n",
    "#Per postcode : cust type: language : season_type\n",
    "lr_model = LinearRegression()\n",
    "#We merge customertype with the new CSV income per postcode to get median income and average income\n",
    "#Based on where the customer lives\n",
    "df_featuresFrame = pd.merge(df_CustomerType,df_Income_per_postcode, how=\"right\" ,on=\"Postcode\")\n",
    "df_featuresFrame=df_featuresFrame.dropna()\n",
    "\n",
    "#We apply scalers to these paramaters (Also cat var??)\n",
    "scaler = StandardScaler(df_featuresFrame)\n",
    "df_featuresFrame[\"AVERAGE_INCOME\"] = df_featuresFrame[\"AVERAGE_INCOME\"].astype(float)\n",
    "df_featuresFrame[\"MEDIAN_INCOME\"] = df_featuresFrame[\"MEDIAN_INCOME\"].astype(float)\n",
    "\n",
    "#Encading cat var\n",
    "label_encoder1 = LabelEncoder()\n",
    "label_encoder1.fit(df_featuresFrame[\"CustomerType\"])\n",
    "def changeLan(lang):\n",
    "    if(lang == \"nl_BE\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1    \n",
    "df_featuresFrame[\"CustomerTypeNum\"] = label_encoder1.transform(df_featuresFrame[\"CustomerType\"])    \n",
    "\n",
    "#0 is dutch 1 speaks french\n",
    "df_featuresFrame[\"Language\"]=df_featuresFrame[\"Language\"].apply(changeLan)\n",
    "print(df_featuresFrame.head(5))\n",
    "\n",
    "scaler.fit(df_featuresFrame[[\"AVERAGE_INCOME\",\"MEDIAN_INCOME\",\"CustomerTypeNum\",\"Language\"]])\n",
    "\n",
    "\n",
    "#I have no idea how to incorprate CUSTOMERTYPENUM and LANGUAGE because they are catogorical vars so idk if this is right\n",
    "lr_model.fit(X=df_featuresFrame[[\"AVERAGE_INCOME\",\"MEDIAN_INCOME\",\"CustomerTypeNum\",\"Language\"]], y=df_featuresFrame[\"CLV\"])\n",
    "lr_model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#Q3 Who are the employees?\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.1 What are the routes of the employees?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3.2 What is the turnover for each employee?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#Q4 What are the routes?\n",
    "########################\n",
    "#Let's start by merging the df_RouteTemplate datdabse with the other two databases (CustomerType and Depotfor closer detail\n",
    "#The merge is done via the equally named column \"HVROUTETEMPLATE_NRID\" in all databases.\n",
    "#However the df_RouteTemplate contains these ID's in the first column, was this was the list of keys from our dictionary\n",
    "#This results in the first column having no columname to merge with other databases. To solve this we can copy this column.\n",
    "#After we copied this column we can add it to our original database, we now have duplicate column with which we can work with.\n",
    "df_RouteTemplate[\"HVROUTETEMPLATE_NRID\"] = df_RouteTemplate.index\n",
    "\n",
    "#next we will merge the two databases df_RouteTemplate and df_CustomerType in order to link our customer and route info\n",
    "df_CustomerType[\"CustomerID\"]=df_CustomerType.index\n",
    "df_Customer_Route = pd.merge(df_CustomerType, df_RouteTemplate, how = \"outer\", on = \"HVROUTETEMPLATE_NRID\")\n",
    "#for future question we will also need the depot so that's why we join them as well\n",
    "df_Customer_Route_Depot = pd.merge(df_Depot, df_Customer_Route, how = \"outer\", on = \"HVROUTETEMPLATE_NRID\")\n",
    "df_CustomerType.head(5)\n",
    "#df_Customer_Route.head(5)\n",
    "#increasing the view of our dataframe, set the parameters if you want less rows to be visible\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.1 How are the customers divided into regions?\n",
    "#here we can see that every customer has its own routenumber, postcode, region, weekorder and dayofweek. \n",
    "#If we make a subselection of our total database and remove all duplicates for our region and postcode,\n",
    "#we can find a database that shows us each region linked to each unique postcode, as we assumed (see picture of map)\n",
    "#all unique postcodes are clustered in 4 groups en each cluster of postcodes corresponds to the same region!\n",
    "#so to answer: The postcode of a customer determines its REGION\n",
    "df_Customer_Route_Depot.drop_duplicates(subset = [\"Postcode\", \"REGION\"]).sort_values(by=\"REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Customer_Route_Depot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-752cbaf12334>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Q4.2 Which customers are assigned to which routes?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_Customer_Route_Depot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"HVROUTETEMPLATE_NRID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"WEEKORDER\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DAYOFWEEK_NRID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"HVROUTETEMPLATE_NRID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"WEEKORDER\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DAYOFWEEK_NRID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_Customer_Route_Depot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"HVROUTETEMPLATE_NRID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"WEEKORDER\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DAYOFWEEK_NRID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_CRV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_CustomerType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_Customer_Route_Depot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"HVROUTETEMPLATE_NRID\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Postcode_x\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CustomerID_x\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CustomerType_x\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Language_x\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Season_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_CRV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CustomerID_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Customer_Route_Depot' is not defined"
     ]
    }
   ],
   "source": [
    "#Q4.2 Which customers are assigned to which routes?\n",
    "df_Customer_Route_Depot.drop_duplicates(subset = [\"HVROUTETEMPLATE_NRID\", \"WEEKORDER\", \"DAYOFWEEK_NRID\"]).sort_values(by=[\"HVROUTETEMPLATE_NRID\", \"WEEKORDER\", \"DAYOFWEEK_NRID\"])\n",
    "df_Customer_Route_Depot.drop_duplicates().sort_values(by=[\"HVROUTETEMPLATE_NRID\", \"WEEKORDER\", \"DAYOFWEEK_NRID\"])\n",
    "df_CRV = pd.merge(df_CustomerType, df_Customer_Route_Depot, on=\"HVROUTETEMPLATE_NRID\").drop(columns=[\"Postcode_x\",\"CustomerID_x\",\"CustomerType_x\",\"Language_x\",\"Season_x\"])\n",
    "df_CRV.sort_values(by=[\"CustomerID_y\"])\n",
    "df_CRV.head(5)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.3 Which routes are assigned to which depots?\n",
    "#In the dataframe below we can see for each depot every single possible route, the total number of routes in the dataframe is\n",
    "#39 which corresponds to the df_RouteTemplate dataframe, where there were 39 possible routes\n",
    "#This shows that every route is linked to a certain depot\n",
    "df_Customer_Route_Depot.drop_duplicates(subset = [\"DEPOT\", \"HVROUTETEMPLATE_NRID\"]).sort_values(by = \"DEPOT\")\n",
    "len(df_Customer_Route_Depot.drop_duplicates(subset = [\"DEPOT\", \"HVROUTETEMPLATE_NRID\"]).sort_values(by = \"DEPOT\").index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#Q5 How can the company improve its service?\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.1 Which customers should be rewarded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.2 Which employees should be rewarded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.3 To which customers should the company send coupons in order to win them back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.4 Are there factors that the company can change in order to decrease the churning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.5 Would it be valuable to recommend (upsell / cross sell) products to a customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.6 Which employees should be assigned to different routes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.7 Which routes should be reassigned to different depots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.8 Which customers should be reassigned to different routes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.9 Which depots should be removed? Where should the company create new depots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.10 Which products should be added / removed from depots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.11 Does customer satisfaction relate to different factors? Can the company respond to these\n",
    "#factors?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e915f0a29dc84041eaeb02b7b1a21c440e37a87b61d44d5e84a515737dc82bc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
